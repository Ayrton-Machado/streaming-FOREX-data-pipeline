"""
Teste da Etapa 5: Feature Engineering AvanÃ§ado
Testa todos os componentes de anÃ¡lise avanÃ§ada
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import asyncio
import sys
import os

# Adiciona o diretÃ³rio raiz ao path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.services.features.advanced_feature_engineer import AdvancedFeatureEngineer
from app.services.analysis.backtesting_engine import (
    BacktestingEngine,
    SimpleMovingAverageStrategy,
    RSIStrategy,
    MACDStrategy
)
from app.services.analysis.feature_importance import FeatureImportanceAnalyzer
from app.services.analysis.pattern_detection import TechnicalPatternDetector

def generate_sample_data(days: int = 100) -> pd.DataFrame:
    """Gera dados de amostra para teste"""
    print(f"ğŸ“Š Gerando {days} dias de dados de amostra...")
    
    # Data range
    dates = pd.date_range(start=datetime.now() - timedelta(days=days), 
                         end=datetime.now(), freq='1H')
    
    # Simula preÃ§os EURUSD
    np.random.seed(42)
    base_price = 1.0800
    
    # Random walk com drift
    returns = np.random.normal(0.0001, 0.005, len(dates))
    prices = [base_price]
    
    for ret in returns[1:]:
        new_price = prices[-1] * (1 + ret)
        prices.append(new_price)
    
    # Cria OHLCV
    df = pd.DataFrame(index=dates)
    df['close'] = prices
    
    # Simula open, high, low
    df['open'] = df['close'].shift(1).fillna(df['close'].iloc[0])
    
    # High/Low baseado em volatilidade
    volatility = np.random.uniform(0.0005, 0.003, len(df))
    df['high'] = df[['open', 'close']].max(axis=1) * (1 + volatility)
    df['low'] = df[['open', 'close']].min(axis=1) * (1 - volatility)
    
    # Volume simulado
    df['volume'] = np.random.uniform(1000, 10000, len(df))
    
    print(f"âœ… Dados gerados: {len(df)} pontos de {df.index[0]} a {df.index[-1]}")
    return df

def test_advanced_feature_engineering():
    """Testa o feature engineering avanÃ§ado"""
    print("\nğŸ”¬ Testando Feature Engineering AvanÃ§ado...")
    
    # Gera dados
    df = generate_sample_data(30)  # 30 dias
    
    # Inicializa feature engineer
    engineer = AdvancedFeatureEngineer()
    
    # Testa indicadores individuais
    print("ğŸ“ˆ Testando indicadores individuais...")
    
    # Momentum indicators
    williams_r = engineer.calculate_williams_r(df)
    print(f"  Williams %R: {len(williams_r.dropna())} valores vÃ¡lidos")
    
    stoch_k, stoch_d = engineer.calculate_stochastic(df)
    print(f"  Stochastic: K={len(stoch_k.dropna())}, D={len(stoch_d.dropna())} valores")
    
    cci = engineer.calculate_cci(df)
    print(f"  CCI: {len(cci.dropna())} valores vÃ¡lidos")
    
    # Trend indicators
    adx = engineer.calculate_adx(df)
    print(f"  ADX: {len(adx.dropna())} valores vÃ¡lidos")
    
    aroon_up, aroon_down = engineer.calculate_aroon(df)
    print(f"  Aroon: Up={len(aroon_up.dropna())}, Down={len(aroon_down.dropna())} valores")
    
    psar = engineer.calculate_parabolic_sar(df)
    print(f"  Parabolic SAR: {len(psar.dropna())} valores vÃ¡lidos")
    
    # Calcula todas as features
    print("ğŸ”§ Calculando todas as features...")
    all_features = engineer.calculate_all_advanced_indicators(df)
    print(f"âœ… Total de features calculadas: {len(all_features)}")
    
    # Gera relatÃ³rio
    print("ğŸ“‹ Gerando relatÃ³rio de features...")
    report = engineer.generate_feature_report(df)
    
    print(f"  - Total de features: {report['total_features']}")
    print(f"  - Top 5 features: {report['top_features'][:5]}")
    print(f"  - Tipos de indicadores: {report['indicator_types']}")
    
    return all_features, report

def test_backtesting():
    """Testa o sistema de backtesting"""
    print("\nğŸ“Š Testando Sistema de Backtesting...")
    
    # Gera dados
    df = generate_sample_data(60)  # 60 dias para backtesting
    
    # Inicializa engine
    engine = BacktestingEngine(initial_capital=10000.0)
    
    # Cria estratÃ©gias
    strategies = [
        SimpleMovingAverageStrategy(10, 20),
        RSIStrategy(14, 30, 70),
        MACDStrategy(12, 26, 9)
    ]
    
    print(f"ğŸ¯ Testando {len(strategies)} estratÃ©gias...")
    
    # Executa backtesting
    results = engine.compare_strategies(df, strategies)
    
    # Mostra resultados
    for strategy_name, result in results.items():
        print(f"\nğŸ“ˆ EstratÃ©gia: {strategy_name}")
        print(f"  - Retorno total: {result.total_return:.2f}%")
        print(f"  - Total de trades: {result.total_trades}")
        print(f"  - Win rate: {result.win_rate:.1f}%")
        print(f"  - Max drawdown: {result.max_drawdown:.2f}%")
        print(f"  - Sharpe ratio: {result.sharpe_ratio:.2f}")
        print(f"  - Profit factor: {result.profit_factor:.2f}")
    
    # Gera relatÃ³rio de performance
    performance_report = engine.generate_performance_report(results)
    print(f"\nğŸ† Melhor estratÃ©gia (retorno): {performance_report['rankings']['total_return'][0]}")
    print(f"ğŸ¯ Melhor estratÃ©gia (Sharpe): {performance_report['rankings']['sharpe_ratio'][0]}")
    
    return results, performance_report

def test_feature_importance():
    """Testa anÃ¡lise de importÃ¢ncia de features"""
    print("\nğŸ” Testando AnÃ¡lise de ImportÃ¢ncia de Features...")
    
    # Gera dados
    df = generate_sample_data(50)  # 50 dias
    
    # Calcula features
    engineer = AdvancedFeatureEngineer()
    features_dict = engineer.calculate_all_advanced_indicators(df)
    features_df = pd.DataFrame(features_dict, index=df.index)
    
    # Define target (retornos futuros)
    target = df['close'].pct_change().shift(-1).dropna()
    
    # Alinha dados
    common_idx = features_df.index.intersection(target.index)
    features_df = features_df.loc[common_idx]
    target = target.loc[common_idx]
    
    print(f"ğŸ“Š Analisando {len(features_df.columns)} features em {len(features_df)} pontos")
    
    # Inicializa analisador
    analyzer = FeatureImportanceAnalyzer()
    
    # Testa mÃ©todos individuais
    print("ğŸ”¬ Testando mÃ©todos de anÃ¡lise...")
    
    # CorrelaÃ§Ã£o
    corr_result = analyzer.analyze_correlation(features_df, target)
    print(f"  - CorrelaÃ§Ã£o: {len(corr_result.top_features)} top features")
    
    # Mutual Information
    mi_result = analyzer.analyze_mutual_information(features_df, target)
    print(f"  - Mutual Info: {len(mi_result.top_features)} top features")
    
    # Random Forest
    rf_result = analyzer.analyze_random_forest(features_df, target)
    print(f"  - Random Forest: {len(rf_result.top_features)} top features")
    
    # AnÃ¡lise compreensiva
    print("ğŸ¯ Executando anÃ¡lise compreensiva...")
    results = analyzer.comprehensive_analysis(features_df, target)
    
    successful_methods = [name for name, result in results.items() 
                         if not result.metadata.get('error')]
    print(f"âœ… MÃ©todos executados com sucesso: {successful_methods}")
    
    # Ranking de consenso
    consensus = analyzer.create_consensus_ranking(results)
    print(f"ğŸ† Top 10 features por consenso:")
    for i, item in enumerate(consensus['consensus_ranking'][:10], 1):
        print(f"  {i:2d}. {item['feature']:20} (score: {item['consensus_score']:.3f})")
    
    return results, consensus

def test_pattern_detection():
    """Testa detecÃ§Ã£o de padrÃµes tÃ©cnicos"""
    print("\nğŸ¨ Testando DetecÃ§Ã£o de PadrÃµes TÃ©cnicos...")
    
    # Gera dados com mais volatilidade para padrÃµes
    df = generate_sample_data(40)  # 40 dias
    
    # Adiciona mais volatilidade para criar padrÃµes
    volatility_boost = np.random.normal(0, 0.01, len(df))
    df['high'] = df['high'] * (1 + abs(volatility_boost))
    df['low'] = df['low'] * (1 - abs(volatility_boost))
    
    print(f"ğŸ“Š Analisando padrÃµes em {len(df)} pontos de dados")
    
    # Inicializa detector
    detector = TechnicalPatternDetector()
    
    # Testa padrÃµes individuais
    print("ğŸ•¯ï¸ Detectando padrÃµes candlestick...")
    
    doji_patterns = detector.detect_doji(df)
    print(f"  - Doji: {len(doji_patterns)} padrÃµes detectados")
    
    hammer_patterns = detector.detect_hammer(df)
    print(f"  - Hammer: {len(hammer_patterns)} padrÃµes detectados")
    
    engulfing_patterns = detector.detect_engulfing_patterns(df)
    print(f"  - Engulfing: {len(engulfing_patterns)} padrÃµes detectados")
    
    star_patterns = detector.detect_star_patterns(df)
    print(f"  - Star patterns: {len(star_patterns)} padrÃµes detectados")
    
    print("ğŸ“ˆ Detectando padrÃµes de grÃ¡fico...")
    
    support_resistance = detector.detect_support_resistance(df)
    print(f"  - Suporte/ResistÃªncia: {len(support_resistance)} nÃ­veis detectados")
    
    trends = detector.detect_trends(df)
    print(f"  - TendÃªncias: {len(trends)} mudanÃ§as detectadas")
    
    breakouts = detector.detect_breakouts(df)
    print(f"  - Breakouts: {len(breakouts)} padrÃµes detectados")
    
    # Detecta todos os padrÃµes
    print("ğŸ¯ Detectando todos os padrÃµes...")
    all_patterns = detector.detect_all_patterns(df)
    
    total_patterns = sum(len(signals) for signals in all_patterns.values())
    print(f"âœ… Total de padrÃµes detectados: {total_patterns}")
    
    # Gera resumo
    summary = detector.generate_pattern_summary(all_patterns)
    print(f"ğŸ“‹ Resumo dos padrÃµes:")
    print(f"  - DistribuiÃ§Ã£o de confianÃ§a: {summary['confidence_distribution']}")
    print(f"  - Qualidade da anÃ¡lise: {summary['analysis_quality']['high_confidence_ratio']:.2f}")
    
    # Mostra padrÃµes recentes
    if summary['recent_patterns']:
        print(f"ğŸ”¥ Ãšltimos 3 padrÃµes detectados:")
        for i, pattern in enumerate(summary['recent_patterns'][:3], 1):
            print(f"  {i}. {pattern['pattern'].upper()} ({pattern['confidence']}) "
                  f"@ {pattern['timestamp'][:16]}")
    
    return all_patterns, summary

def test_api_integration():
    """Testa integraÃ§Ã£o com a API"""
    print("\nğŸŒ Testando IntegraÃ§Ã£o com API...")
    
    try:
        # Importa mÃ³dulos da API
        from app.api.advanced_features import (
            FeatureEngineeringRequest,
            BacktestRequest,
            FeatureImportanceRequest,
            PatternDetectionRequest
        )
        
        print("âœ… Modelos Pydantic importados com sucesso")
        
        # Testa criaÃ§Ã£o de requests
        feature_req = FeatureEngineeringRequest(
            symbol="EURUSD",
            indicators=["williams_r", "stochastic_k", "adx"]
        )
        print(f"âœ… FeatureEngineeringRequest: {feature_req.symbol}")
        
        backtest_req = BacktestRequest(
            symbol="EURUSD",
            strategies=["sma", "rsi"],
            initial_capital=10000.0
        )
        print(f"âœ… BacktestRequest: {len(backtest_req.strategies)} estratÃ©gias")
        
        importance_req = FeatureImportanceRequest(
            symbol="EURUSD",
            methods=["correlation", "random_forest"]
        )
        print(f"âœ… FeatureImportanceRequest: {len(importance_req.methods)} mÃ©todos")
        
        pattern_req = PatternDetectionRequest(
            symbol="EURUSD",
            min_confidence="medium"
        )
        print(f"âœ… PatternDetectionRequest: confianÃ§a {pattern_req.min_confidence}")
        
        print("ğŸ¯ Todos os modelos de API funcionando corretamente")
        
    except ImportError as e:
        print(f"âš ï¸ Erro na importaÃ§Ã£o da API: {e}")
        print("   (Normal se FastAPI nÃ£o estiver instalado)")
    
    return True

def main():
    """Executa todos os testes"""
    print("ğŸš€ TESTE COMPLETO - ETAPA 5: FEATURE ENGINEERING AVANÃ‡ADO")
    print("=" * 60)
    
    start_time = datetime.now()
    
    try:
        # Teste 1: Feature Engineering
        features, feature_report = test_advanced_feature_engineering()
        
        # Teste 2: Backtesting
        backtest_results, performance_report = test_backtesting()
        
        # Teste 3: Feature Importance
        importance_results, consensus = test_feature_importance()
        
        # Teste 4: Pattern Detection
        patterns, pattern_summary = test_pattern_detection()
        
        # Teste 5: API Integration
        api_test = test_api_integration()
        
        # Resumo final
        print("\n" + "=" * 60)
        print("ğŸ¯ RESUMO DOS TESTES")
        print("=" * 60)
        
        print(f"âœ… Feature Engineering: {len(features)} features calculadas")
        print(f"âœ… Backtesting: {len(backtest_results)} estratÃ©gias testadas")
        print(f"âœ… Feature Importance: {len(importance_results)} mÃ©todos executados")
        print(f"âœ… Pattern Detection: {sum(len(s) for s in patterns.values())} padrÃµes detectados")
        print(f"âœ… API Integration: {'Sucesso' if api_test else 'Falhou'}")
        
        # EstatÃ­sticas
        execution_time = datetime.now() - start_time
        print(f"\nâ±ï¸ Tempo total de execuÃ§Ã£o: {execution_time.total_seconds():.2f}s")
        
        # Top insights
        print(f"\nğŸ† TOP INSIGHTS:")
        print(f"  - Melhor estratÃ©gia: {performance_report['rankings']['total_return'][0]}")
        print(f"  - Top feature: {consensus['top_features'][0] if consensus['top_features'] else 'N/A'}")
        print(f"  - PadrÃµes high confidence: {pattern_summary['confidence_distribution']['high']}")
        
        print(f"\nğŸ‰ ETAPA 5 COMPLETADA COM SUCESSO!")
        print(f"   Sistema de Feature Engineering AvanÃ§ado totalmente funcional")
        return True
        
    except Exception as e:
        print(f"\nâŒ ERRO NO TESTE: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)